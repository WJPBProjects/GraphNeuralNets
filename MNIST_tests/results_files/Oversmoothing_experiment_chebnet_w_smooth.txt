Seed: 3
 [{'test_loss': 1.0468379259109497, 'test_acc': 0.6215000152587891}]
 
Seed: 4
 [{'test_loss': 1.0572834014892578, 'test_acc': 0.6266000270843506}]
 
Seed: 8
 [{'test_loss': 1.077212929725647, 'test_acc': 0.6079999804496765}]
 
Seed: 9
 [{'test_loss': 1.0897899866104126, 'test_acc': 0.611299991607666}]
 
Seed: 27
 [{'test_loss': 1.0764801502227783, 'test_acc': 0.6147000193595886}]
 
END
80 epochs

for seed in rand_seeds:
    #re-seed everything
    pl.seed_everything(seed, workers=True)
    
    #setup data
    mnist_data = MNISTDataModule(data_dir = './MNIST_data/',
                                 batch_size = 40
                                )
    
    #setup model
    kernel_size = 5

    model = ChebNet(hidden_channels = 64, 
                num_node_features = 1, 
                num_classes = 10,
                k_size = 5,
                CBS_initial_neighb_distance = 1, 
                CBS_epochs = 25,
                starting_own_weight = 0,
                weight_epochs = 5, 
                weight_incr = 0.2
               )

    
    checkpoint_callback = ModelCheckpoint(
        monitor='val_loss',
        save_top_k=1,
        mode='min',
    )
    
    
    #setup trainer
    callbacks_list = [checkpoint_callback]
    
    trainer = pl.Trainer(gpus=1, 
                     deterministic=True, 
                     min_epochs = num_epochs,
                     max_epochs = num_epochs, 
                     callbacks=callbacks_list
                    )
    
    #fit
    trainer.fit(model, mnist_data)
    
    #test & save
    test_vals = trainer.test(model = model)
    
    with open(results_filename, "a") as file_object:
        file_object.write(f'Seed: {seed}\n {test_vals}\n \n')